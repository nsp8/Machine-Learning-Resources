{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Kaggle Notebook Info**\n> This Python 3 environment comes with many helpful analytics libraries installed\n> It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n> For example, here's several helpful packages to load\n```python\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n```\n> Input data files are available in the read-only \"../input/\" directory\n> For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n```python\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n```\n> You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n> You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-15T22:26:43.663069Z","iopub.execute_input":"2024-07-15T22:26:43.663634Z","iopub.status.idle":"2024-07-15T22:26:43.672505Z","shell.execute_reply.started":"2024-07-15T22:26:43.663591Z","shell.execute_reply":"2024-07-15T22:26:43.670797Z"}}},{"cell_type":"code","source":"!pip install supabase","metadata":{"execution":{"iopub.status.busy":"2024-07-23T22:20:39.429588Z","iopub.execute_input":"2024-07-23T22:20:39.429967Z","iopub.status.idle":"2024-07-23T22:21:06.177064Z","shell.execute_reply.started":"2024-07-23T22:20:39.429936Z","shell.execute_reply":"2024-07-23T22:21:06.175797Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Collecting supabase\n  Downloading supabase-2.5.3-py3-none-any.whl.metadata (9.3 kB)\nCollecting gotrue<3.0,>=1.3 (from supabase)\n  Downloading gotrue-2.6.0-py3-none-any.whl.metadata (6.0 kB)\nRequirement already satisfied: httpx<0.28,>=0.24 in /opt/conda/lib/python3.10/site-packages (from supabase) (0.27.0)\nCollecting postgrest<0.17.0,>=0.14 (from supabase)\n  Downloading postgrest-0.16.9-py3-none-any.whl.metadata (5.1 kB)\nCollecting realtime<2.0.0,>=1.0.0 (from supabase)\n  Downloading realtime-1.0.6-py3-none-any.whl.metadata (2.6 kB)\nCollecting storage3<0.8.0,>=0.5.3 (from supabase)\n  Downloading storage3-0.7.7-py3-none-any.whl.metadata (1.9 kB)\nCollecting supafunc<0.5.0,>=0.3.1 (from supabase)\n  Downloading supafunc-0.4.7-py3-none-any.whl.metadata (1.2 kB)\nRequirement already satisfied: pydantic<3,>=1.10 in /opt/conda/lib/python3.10/site-packages (from gotrue<3.0,>=1.3->supabase) (2.5.3)\nRequirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<0.28,>=0.24->supabase) (4.2.0)\nRequirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<0.28,>=0.24->supabase) (2024.7.4)\nRequirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<0.28,>=0.24->supabase) (1.0.5)\nRequirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx<0.28,>=0.24->supabase) (3.6)\nRequirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<0.28,>=0.24->supabase) (1.3.0)\nRequirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28,>=0.24->supabase) (0.14.0)\nRequirement already satisfied: deprecation<3.0.0,>=2.1.0 in /opt/conda/lib/python3.10/site-packages (from postgrest<0.17.0,>=0.14->supabase) (2.1.0)\nCollecting strenum<0.5.0,>=0.4.9 (from postgrest<0.17.0,>=0.14->supabase)\n  Downloading StrEnum-0.4.15-py3-none-any.whl.metadata (5.3 kB)\nRequirement already satisfied: python-dateutil<3.0.0,>=2.8.1 in /opt/conda/lib/python3.10/site-packages (from realtime<2.0.0,>=1.0.0->supabase) (2.9.0.post0)\nCollecting typing-extensions<5.0.0,>=4.12.2 (from realtime<2.0.0,>=1.0.0->supabase)\n  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: websockets<13,>=11 in /opt/conda/lib/python3.10/site-packages (from realtime<2.0.0,>=1.0.0->supabase) (12.0)\nRequirement already satisfied: packaging in /opt/conda/lib/python3.10/site-packages (from deprecation<3.0.0,>=2.1.0->postgrest<0.17.0,>=0.14->supabase) (21.3)\nCollecting h2<5,>=3 (from httpx[http2]<0.28,>=0.24->gotrue<3.0,>=1.3->supabase)\n  Downloading h2-4.1.0-py3-none-any.whl.metadata (3.6 kB)\nRequirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.10->gotrue<3.0,>=1.3->supabase) (0.6.0)\nRequirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1.10->gotrue<3.0,>=1.3->supabase) (2.14.6)\nRequirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil<3.0.0,>=2.8.1->realtime<2.0.0,>=1.0.0->supabase) (1.16.0)\nRequirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<0.28,>=0.24->supabase) (1.2.0)\nCollecting hyperframe<7,>=6.0 (from h2<5,>=3->httpx[http2]<0.28,>=0.24->gotrue<3.0,>=1.3->supabase)\n  Downloading hyperframe-6.0.1-py3-none-any.whl.metadata (2.7 kB)\nCollecting hpack<5,>=4.0 (from h2<5,>=3->httpx[http2]<0.28,>=0.24->gotrue<3.0,>=1.3->supabase)\n  Downloading hpack-4.0.0-py3-none-any.whl.metadata (2.5 kB)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging->deprecation<3.0.0,>=2.1.0->postgrest<0.17.0,>=0.14->supabase) (3.1.1)\nDownloading supabase-2.5.3-py3-none-any.whl (16 kB)\nDownloading gotrue-2.6.0-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.6/45.6 kB\u001b[0m \u001b[31m732.8 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n\u001b[?25hDownloading postgrest-0.16.9-py3-none-any.whl (21 kB)\nDownloading realtime-1.0.6-py3-none-any.whl (9.0 kB)\nDownloading storage3-0.7.7-py3-none-any.whl (16 kB)\nDownloading supafunc-0.4.7-py3-none-any.whl (6.2 kB)\nDownloading StrEnum-0.4.15-py3-none-any.whl (8.9 kB)\nDownloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\nDownloading h2-4.1.0-py3-none-any.whl (57 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading hpack-4.0.0-py3-none-any.whl (32 kB)\nDownloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\nInstalling collected packages: strenum, typing-extensions, hyperframe, hpack, realtime, h2, supafunc, storage3, postgrest, gotrue, supabase\n  Attempting uninstall: typing-extensions\n    Found existing installation: typing_extensions 4.9.0\n    Uninstalling typing_extensions-4.9.0:\n      Successfully uninstalled typing_extensions-4.9.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ncudf 24.6.1 requires cubinlinker, which is not installed.\ncudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ncudf 24.6.1 requires ptxcompiler, which is not installed.\ncuml 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ndask-cudf 24.6.1 requires cupy-cuda11x>=12.0.0, which is not installed.\ntensorflow-decision-forests 1.8.1 requires wurlitzer, which is not installed.\napache-beam 2.46.0 requires dill<0.3.2,>=0.3.1.1, but you have dill 0.3.8 which is incompatible.\napache-beam 2.46.0 requires numpy<1.25.0,>=1.14.3, but you have numpy 1.26.4 which is incompatible.\napache-beam 2.46.0 requires pyarrow<10.0.0,>=3.0.0, but you have pyarrow 16.1.0 which is incompatible.\ncudf 24.6.1 requires cuda-python<12.0a0,>=11.7.1, but you have cuda-python 12.5.0 which is incompatible.\njupyterlab 4.2.3 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\njupyterlab-lsp 5.1.0 requires jupyter-lsp>=2.0.0, but you have jupyter-lsp 1.5.1 which is incompatible.\ntensorflow 2.15.0 requires keras<2.16,>=2.15.0, but you have keras 3.4.1 which is incompatible.\nydata-profiling 4.6.4 requires numpy<1.26,>=1.16.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed gotrue-2.6.0 h2-4.1.0 hpack-4.0.0 hyperframe-6.0.1 postgrest-0.16.9 realtime-1.0.6 storage3-0.7.7 strenum-0.4.15 supabase-2.5.3 supafunc-0.4.7 typing-extensions-4.12.2\n","output_type":"stream"}]},{"cell_type":"code","source":"import numpy as np\nimport ray\nimport requests\nfrom torchvision import transforms\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights\nfrom torchvision.transforms.functional import convert_image_dtype, to_pil_image, to_tensor\nfrom torchvision.utils import draw_bounding_boxes\nfrom PIL import Image","metadata":{"execution":{"iopub.status.busy":"2024-07-23T22:21:06.179805Z","iopub.execute_input":"2024-07-23T22:21:06.180236Z","iopub.status.idle":"2024-07-23T22:21:11.649164Z","shell.execute_reply.started":"2024-07-23T22:21:06.180194Z","shell.execute_reply":"2024-07-23T22:21:11.648209Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stderr","text":"2024-07-23 22:21:07,094\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n","output_type":"stream"}]},{"cell_type":"code","source":"from dataclasses import dataclass\nfrom io import BytesIO, BufferedReader\nfrom kaggle_secrets import UserSecretsClient\nfrom supabase import create_client, Client\n\nuser_secrets = UserSecretsClient()\ndata_store_url = user_secrets.get_secret(\"SUPABASE_URL\")\ndata_store_key = user_secrets.get_secret(\"SUPABASE_KEY\")\nsupabase_client = create_client(data_store_url, data_store_key)\n\n\ndef store_data_in_bucket(data, file_path, bucket_name=\"test_bucket\"):\n    def to_binary_stream(d):\n        b_handle = BytesIO()\n        b_handle.write(d)\n        help(b_handle.write)\n        b_handle.seek(0)\n        return BufferedReader(b_handle)\n\n    def file_exists():\n        file_parts = file_path.split(\"/\")\n        folder = \"/\".join(file_parts[:-1])\n        for file in supabase_client.storage.from_(bucket_name).list(path=folder):\n            if file[\"name\"] == file_parts[-1]:\n                return True\n        return False\n\n    if not supabase_client.storage.get_bucket(bucket_name):\n        supabase_client.storage.create_bucket(bucket_name)\n    # upload file\n    file_options = {\n        \"content-type\": \"application/vnd.apache.parquet\",\n        \"cache-control\": \"3600\",\n        \"upsert\": \"true\"\n    }\n    if file_exists():\n        supabase_client.storage.from_(\"test_bucket\").update(\n            file=to_binary_stream(data),\n            path=file_path,\n            file_options=file_options\n        )\n    else:\n        supabase_client.storage.from_(\"test_bucket\").upload(\n            file=to_binary_stream(data),\n            path=file_path,\n            file_options=file_options\n        )\n\n\ndef preprocess(data: dict[str, np.ndarray]):\n    weights = FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n    preprocessor: transforms.Compose = transforms.Compose(\n        [transforms.ToTensor(), weights.transforms()]\n    )\n    return {\n        \"image\": data[\"image\"],\n        \"transformed\": preprocessor(data[\"image\"])\n    }\n\n\n@dataclass\nclass ObjectDetectionModel:\n    weights = FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n    model = fasterrcnn_resnet50_fpn_v2(weights=weights, box_score_thresh=0.9)\n    preprocessor: transforms.Compose = transforms.Compose(\n        [transforms.ToTensor(), weights.transforms()]\n    )\n\n    def __call__(self, input_batch: dict[str, np.ndarray]):\n        batch = [torch.from_numpy(img) for img in input_batch[\"transformed\"]]\n        if torch.cuda.is_available():\n            batch = [img.cuda() for img in batch]\n        predictions = self.model(batch)\n        return {\n            \"image\": input_batch[\"image\"],\n            \"labels\": [p[\"labels\"].detach().cpu().numpy() for p in predictions],\n            \"boxes\": [p[\"boxes\"].detach().cpu().numpy() for p in predictions],\n        }\n\n    def _eval(self):\n        if torch.cuda.is_available():\n            self.model = self.model.cuda()\n        self.model.eval()\n        return self\n\n    def visualize_detection(self, image_object):\n        transformed_image = transforms.Compose([transforms.PILToTensor()])(image_object)\n        preprocess = self.weights.transforms()\n        batch = preprocess(transformed_image)\n        prediction = self.model(batch)[0]\n        labels = [self.weights.meta[\"categories\"][i] for i in prediction[\"labels\"]]\n        bounding_boxes = draw_bounding_boxes(\n            transformed_image,\n            boxes=prediction[\"boxes\"],\n            labels=labels,\n            colors=\"red\",\n            width=4\n        )\n        display(to_pil_image(bounding_boxes.detach()))\n\n\ndef process_data(concurrency=4, batch_size=4, num_gpus=1):\n    raw_dataset = ray.data.read_images(\"s3://anonymous@air-example-data/AnimalDetection/JPEGImages\")\n    preprocessed_data = raw_dataset.map(preprocess)  # function=based UDFs run as short-running ray \"tasks\"\n    dataset = preprocessed_data.map_batches(\n        ObjectDetectionModel,  # class-based UDFs run as long-running ray \"actors\"\n        concurrency=concurrency,  # number of GPUs (in cluster)\n        batch_size=batch_size,\n        num_gpus=num_gpus\n    )\n    return dataset\n\n\ndef show_sample(dataset, batch_size=2):\n    batch = dataset.take_batch(batch_size=batch_size)\n    for image, labels, boxes in zip(batch[\"image\"], batch[\"labels\"], batch[\"boxes\"]):\n        img = convert_image_dtype(to_tensor(image), torch.uint8)\n        labels = [weights.meta[\"categories\"][i] for i in labels]\n        boxes = torch.from_numpy(boxes)\n        image_object = to_pil_image(draw_bounding_boxes(\n            img, boxes, labels=labels, width=4\n        ))\n        display(image_object)\n\n\ndef main():\n    dataset = process_data()\n    show_sample(dataset)\n    try:\n        store_data_in_bucket(\n            file_path=\"data/object_detection_dataset.parquet\"\n        )\n    except Exception as e:\n        print(f\"Could not upload file: {e}\")\n    finally:\n        return dataset\n\n\ntransformed_dataset = main()","metadata":{"execution":{"iopub.status.busy":"2024-07-23T22:21:11.650422Z","iopub.execute_input":"2024-07-23T22:21:11.651127Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/fasterrcnn_resnet50_fpn_v2_coco-dd69338a.pth\" to /root/.cache/torch/hub/checkpoints/fasterrcnn_resnet50_fpn_v2_coco-dd69338a.pth\n100%|██████████| 167M/167M [00:01<00:00, 144MB/s]  \n2024-07-23 22:21:16,148\tINFO util.py:124 -- Outdated packages:\n  ipywidgets==7.7.1 found, needs ipywidgets>=8\nRun `pip install -U ipywidgets`, then restart the notebook server for rich notebook output.\n2024-07-23 22:21:29,695\tINFO worker.py:1724 -- Started a local Ray instance.\n2024-07-23 22:21:42,097\tINFO set_read_parallelism.py:115 -- Using autodetected parallelism=200 for stage ReadImage to satisfy DataContext.get_current().min_parallelism=200.\n2024-07-23 22:21:42,099\tINFO streaming_executor.py:112 -- Executing DAG InputDataBuffer[Input] -> TaskPoolMapOperator[ReadImage->Map(preprocess)] -> ActorPoolMapOperator[MapBatches(ObjectDetectionModel)] -> LimitOperator[limit=2]\n2024-07-23 22:21:42,101\tINFO streaming_executor.py:113 -- Execution config: ExecutionOptions(resource_limits=ExecutionResources(cpu=None, gpu=None, object_store_memory=None), exclude_resources=ExecutionResources(cpu=0, gpu=0, object_store_memory=0), locality_with_output=False, preserve_order=False, actor_locality_enabled=True, verbose_progress=False)\n2024-07-23 22:21:42,103\tINFO streaming_executor.py:115 -- Tip: For detailed progress reporting, run `ray.data.DataContext.get_current().execution_options.verbose_progress = True`\n2024-07-23 22:21:45,404\tINFO actor_pool_map_operator.py:114 -- MapBatches(ObjectDetectionModel): Waiting for 4 pool actors to start...\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}