{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30746,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## **Kaggle Notebook Info**\n> This Python 3 environment comes with many helpful analytics libraries installed\n> It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n> For example, here's several helpful packages to load\n```python\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n```\n> Input data files are available in the read-only \"../input/\" directory\n> For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n```python\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n```\n> You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n> You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-07-15T22:26:43.663069Z","iopub.execute_input":"2024-07-15T22:26:43.663634Z","iopub.status.idle":"2024-07-15T22:26:43.672505Z","shell.execute_reply.started":"2024-07-15T22:26:43.663591Z","shell.execute_reply":"2024-07-15T22:26:43.670797Z"}}},{"cell_type":"code","source":"!pip install supabase","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from dataclasses import dataclass\nfrom io import BytesIO, BufferedReader\n\nfrom kaggle_secrets import UserSecretsClient\nfrom supabase import create_client, Client\nimport numpy as np\nimport ray\nimport requests\nimport torch\nfrom torchvision import transforms\nfrom torchvision.models.detection import fasterrcnn_resnet50_fpn_v2, FasterRCNN_ResNet50_FPN_V2_Weights\nfrom torchvision.transforms.functional import convert_image_dtype, to_pil_image, to_tensor\nfrom torchvision.utils import draw_bounding_boxes\nfrom PIL import Image","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"try:\n    ray.init(num_cpus=2, num_gpus=1)\nexcept RuntimeError:\n    ray.shutdown()\n    ray.init(num_cpus=4, num_gpus=2)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"user_secrets = UserSecretsClient()\ndata_store_url = user_secrets.get_secret(\"SUPABASE_URL\")\ndata_store_key = user_secrets.get_secret(\"SUPABASE_KEY\")\nsupabase_client = create_client(data_store_url, data_store_key)\n\n\ndef store_data_in_bucket(data, file_path, bucket_name=\"test_bucket\"):\n    def to_binary_stream(d):\n        b_handle = BytesIO()\n        b_handle.write(d)\n        help(b_handle.write)\n        b_handle.seek(0)\n        return BufferedReader(b_handle)\n\n    def file_exists():\n        file_parts = file_path.split(\"/\")\n        folder = \"/\".join(file_parts[:-1])\n        for file in supabase_client.storage.from_(bucket_name).list(path=folder):\n            if file[\"name\"] == file_parts[-1]:\n                return True\n        return False\n\n    if not supabase_client.storage.get_bucket(bucket_name):\n        supabase_client.storage.create_bucket(bucket_name)\n    # upload file\n    file_options = {\n        \"content-type\": \"application/vnd.apache.parquet\",\n        \"cache-control\": \"3600\",\n        \"upsert\": \"true\"\n    }\n    if file_exists():\n        supabase_client.storage.from_(\"test_bucket\").update(\n            file=to_binary_stream(data),\n            path=file_path,\n            file_options=file_options\n        )\n    else:\n        supabase_client.storage.from_(\"test_bucket\").upload(\n            file=to_binary_stream(data),\n            path=file_path,\n            file_options=file_options\n        )\n\n\ndef preprocess(data: dict[str, np.ndarray]):\n    weights = FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n    preprocessor: transforms.Compose = transforms.Compose(\n        [transforms.ToTensor(), weights.transforms()]\n    )\n    return {\n        \"image\": data[\"image\"],\n        \"transformed\": preprocessor(data[\"image\"])\n    }\n\n\n@dataclass\nclass ObjectDetectionModel:\n    weights = FasterRCNN_ResNet50_FPN_V2_Weights.DEFAULT\n    model = fasterrcnn_resnet50_fpn_v2(weights=weights, box_score_thresh=0.9)\n    preprocessor: transforms.Compose = transforms.Compose(\n        [transforms.ToTensor(), weights.transforms()]\n    )\n\n    def __call__(self, input_batch: dict[str, np.ndarray]):\n        batch = [torch.from_numpy(img) for img in input_batch[\"transformed\"]]\n        if torch.cuda.is_available():\n            batch = [img.cuda() for img in batch]\n        predictions = self.model(batch)\n        return {\n            \"image\": input_batch[\"image\"],\n            \"labels\": [p[\"labels\"].detach().cpu().numpy() for p in predictions],\n            \"boxes\": [p[\"boxes\"].detach().cpu().numpy() for p in predictions],\n        }\n\n    def _eval(self):\n        if torch.cuda.is_available():\n            self.model = self.model.cuda()\n        self.model.eval()\n        return self\n\n    def visualize_detection(self, image_object):\n        transformed_image = transforms.Compose([transforms.PILToTensor()])(image_object)\n        preprocess = self.weights.transforms()\n        batch = preprocess(transformed_image)\n        prediction = self.model(batch)[0]\n        labels = [self.weights.meta[\"categories\"][i] for i in prediction[\"labels\"]]\n        bounding_boxes = draw_bounding_boxes(\n            transformed_image,\n            boxes=prediction[\"boxes\"],\n            labels=labels,\n            colors=\"red\",\n            width=4\n        )\n        display(to_pil_image(bounding_boxes.detach()))\n\n\ndef process_data(concurrency=4, batch_size=4, num_gpus=1):\n    raw_dataset = ray.data.read_images(\"s3://anonymous@air-example-data/AnimalDetection/JPEGImages\")\n    preprocessed_data = raw_dataset.map(preprocess)  # function=based UDFs run as short-running ray \"tasks\"\n    dataset = preprocessed_data.map_batches(\n        ObjectDetectionModel,  # class-based UDFs run as long-running ray \"actors\"\n        concurrency=concurrency,  # number of parallel actors\n        batch_size=batch_size,\n        num_gpus=num_gpus\n    )\n    return dataset\n\n\ndef show_sample(dataset, batch_size=2):\n    batch = dataset.take_batch(batch_size=batch_size)\n    for image, labels, boxes in zip(batch[\"image\"], batch[\"labels\"], batch[\"boxes\"]):\n        img = convert_image_dtype(to_tensor(image), torch.uint8)\n        labels = [weights.meta[\"categories\"][i] for i in labels]\n        boxes = torch.from_numpy(boxes)\n        image_object = to_pil_image(draw_bounding_boxes(\n            img, boxes, labels=labels, width=4\n        ))\n        display(image_object)\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def main(concurrency=4, batch_size=4, num_gpus=1):\n    dataset = process_data(\n        concurrency=concurrency, \n        batch_size=batch_size, \n        num_gpus=num_gpus\n    )\n    show_sample(dataset)\n    try:\n        store_data_in_bucket(\n            file_path=\"data/object_detection_dataset.parquet\"\n        )\n    except Exception as e:\n        print(f\"Could not upload file: {e}\")\n    finally:\n        return dataset\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"transformed_dataset = main(concurrency=2, batch_size=2, num_gpus=1)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}